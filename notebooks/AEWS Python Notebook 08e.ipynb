{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEWS Python Notebook 08e: AEWS miscellanea\n",
    "\n",
    "**Author**: Eric Lehmann, CSIRO Data61  \n",
    "**Date**:  July 01, 2016\n",
    "\n",
    "**Note**: The Python code below is \"rudimentary\" etc. etc. Priority is here given to code interpretability rather than execution efficiency.\n",
    "\n",
    "**Note**: this notebook should be accessible and viewable at [https://github.com/eric542/agdc_v2/tree/master/notebooks](https://github.com/eric542/agdc_v2/tree/master/notebooks).\n",
    "\n",
    "## Summary\n",
    "\n",
    "Building up on the concepts introduced in the previous notebooks in this series, we work out the remaining components of the AEWS implementation $-$ see *'AEWS Python Notebook 08a'* for details of these components. The contents summary for the present notebook is given below.\n",
    "\n",
    "**Abstract $-$** From an AEWS perspective, an adequate storage mode is to save the WQ data as a netCDF dataset that includes a time series of WQ maps. As new Landsat imagery is made available on the AGDC, and subsequently processed by the AEWS routines, new WQ maps will need to be appended to the existing netCDF time series. This notebook (08e) investigates a couple of ways this can be achieved using Python.\n",
    "\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "This (Jupyter) notebook was written for use on the NCI's VDI system, with the following pre-loaded module:\n",
    "\n",
    "```\n",
    " $ module use /g/data/v10/public/modules/modulefiles --append\n",
    " $ module load agdc-py2-prod \n",
    "```\n",
    "\n",
    "**NOTE**: the specific module loaded here (`agdc-py2-prod`) is different from the module loaded in earlier notebooks (`agdc-py2-dev`)! While the earlier module contained only Landsat 5 data, the `agdc-py2-prod` module links to a (different) AGDC database containing the following NBART/NBAR/PQA datasets:\n",
    "\n",
    "* Landsat 8: 2013\n",
    "* Landsat 7: 2013\n",
    "* Landsat 5: 2006/2007\n",
    "\n",
    "It is unclear whether the API functions in these 2 modules are identical or represent different versions.\n",
    "\n",
    "**NOTE 2**: as of mid-June 2016, changes were made to the AGDC API v2.0, and the above Landsat datasets (and related API functions) can now be accessed through the module `agdc-py2-prod/1.0.3` (pre-major-change version). How long this module will remain accessible and/or when it will be replaced with the formal v2.0 API is still unclear at this time (June 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div.warn { background-color: #e8c9c9; border-left: 5px solid #c27070; padding: 0.5em }\n",
       "    div.note { background-color: #cce0ff; border-left: 5px solid #5c85d6; padding: 0.5em }\n",
       "    div.info { background-color: #ffe680; border-left: 5px solid #cca300; padding: 0.5em }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html  # Definitions for some pretty text boxes...\n",
    "<style>\n",
    "    div.warn { background-color: #e8c9c9; border-left: 5px solid #c27070; padding: 0.5em }\n",
    "    div.note { background-color: #cce0ff; border-left: 5px solid #5c85d6; padding: 0.5em }\n",
    "    div.info { background-color: #ffe680; border-left: 5px solid #cca300; padding: 0.5em }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "from netCDF4 import date2num\n",
    "from datetime import datetime\n",
    "\n",
    "from netCDF4 import Dataset, num2date\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from pprint import pprint\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating a netCDF dataset: method 1\n",
    "\n",
    "### Setting up the netCDF dataset for appending\n",
    "\n",
    "New time slices can be appended to an existing netCDF dataset by defining an \"unlimited\" time dimension. Let's demonstrate this by first creating a test netCDF file `'test.nc'`. This dataset will have 3 dimensions: time, lat and lon, the first of which is defined as unlimited, i.e. it will grow automatically as new data is appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp = Dataset(\"test.nc\", \"w\")\n",
    "time = rootgrp.createDimension(\"time\", None)   # using 'None' indicates the dimension is unlimited\n",
    "lat = rootgrp.createDimension(\"lat\", 73)\n",
    "lon = rootgrp.createDimension(\"lon\", 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): time(0), lat(73), lon(144)\n",
      "    variables(dimensions): \n",
      "    groups: \n",
      "\n",
      "OrderedDict([('time', <type 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n",
      "), ('lat', <type 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\n",
      "), ('lon', <type 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\n",
      ")])\n",
      "\n",
      "Is the 'time' variable unlimited? True\n"
     ]
    }
   ],
   "source": [
    "print ( rootgrp )\n",
    "print ( rootgrp.dimensions )\n",
    "print ( \"\\nIs the 'time' variable unlimited?\", time.isunlimited() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the `time`, `latitude`, `longitude` variables, as well as the main `temp` variable of 3D data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, lat, lon)\n",
      "unlimited dimensions: time\n",
      "current shape = (0, 73, 144)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",))\n",
    "latitudes = rootgrp.createVariable(\"latitude\",\"f4\",(\"lat\",))\n",
    "longitudes = rootgrp.createVariable(\"longitude\",\"f4\",(\"lon\",))\n",
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"lat\",\"lon\",))\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('time', <type 'netCDF4._netCDF4.Variable'>\n",
       "              float64 time(time)\n",
       "              unlimited dimensions: time\n",
       "              current shape = (0,)\n",
       "              filling on, default _FillValue of 9.96920996839e+36 used),\n",
       "             ('latitude', <type 'netCDF4._netCDF4.Variable'>\n",
       "              float32 latitude(lat)\n",
       "              unlimited dimensions: \n",
       "              current shape = (73,)\n",
       "              filling on, default _FillValue of 9.96920996839e+36 used),\n",
       "             ('longitude', <type 'netCDF4._netCDF4.Variable'>\n",
       "              float32 longitude(lon)\n",
       "              unlimited dimensions: \n",
       "              current shape = (144,)\n",
       "              filling on, default _FillValue of 9.96920996839e+36 used),\n",
       "             ('temp', <type 'netCDF4._netCDF4.Variable'>\n",
       "              float32 temp(time, lat, lon)\n",
       "              unlimited dimensions: time\n",
       "              current shape = (0, 73, 144)\n",
       "              filling on, default _FillValue of 9.96920996839e+36 used)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootgrp.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<type 'netCDF4._netCDF4.Variable'>\n",
       "float32 latitude(lat)\n",
       "unlimited dimensions: \n",
       "current shape = (73,)\n",
       "filling on, default _FillValue of 9.96920996839e+36 used"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
      " -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n",
      " -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --]\n"
     ]
    }
   ],
   "source": [
    "print(latitudes[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python variable `latitudes` (for instance) is a netCDF4 variable somehow linked to the netCDF file `'test.nc'`. Setting values for this variable automatically writes them to the `.nc` file (upon closing the connection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latitudes[:] = np.arange(-90,91,2.5)\n",
    "longitudes[:] = np.arange(-180,180,2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length / size of the variables with unlimited dimension automatically grows as new data is appended / added to the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 73, 144) (0,)\n",
      "[]\n",
      "\n",
      " (5, 73, 144) (5,)\n",
      "[-- -- -- -- --]\n"
     ]
    }
   ],
   "source": [
    "print( temp.shape, times.shape )\n",
    "print( times[:] )\n",
    "\n",
    "temp[0:5,:,:] = uniform(size=(5,73,144))   # some random data\n",
    "\n",
    "print( \"\\n\", temp.shape, times.shape )\n",
    "print( times[:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24164586,  0.53466713,  0.89016908, ...,  0.51961076,\n",
       "         0.91276568,  0.23320143],\n",
       "       [ 0.68931675,  0.82504773,  0.79529351, ...,  0.78653747,\n",
       "         0.69598752,  0.35384986],\n",
       "       [ 0.60408092,  0.03871369,  0.94179893, ...,  0.73702049,\n",
       "         0.15689316,  0.82223141],\n",
       "       ..., \n",
       "       [ 0.30853307,  0.97341442,  0.57557809, ...,  0.56061757,\n",
       "         0.52724916,  0.38175559],\n",
       "       [ 0.74199027,  0.82460821,  0.01898139, ...,  0.34432012,\n",
       "         0.10491152,  0.55185574],\n",
       "       [ 0.58114558,  0.94513285,  0.18880354, ...,  0.23026513,\n",
       "         0.50431281,  0.41810608]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define attributes for each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitudes.units = \"degrees north\"\n",
    "longitudes.units = \"degrees east\"\n",
    "temp.units = \"Z\"\n",
    "times.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "times.calendar = \"gregorian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set the values of the `time` variable, with some plausible date values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some random dates:\n",
      " [datetime.datetime(2001, 3, 1, 0, 0), datetime.datetime(2001, 3, 1, 12, 0), datetime.datetime(2001, 3, 2, 0, 0), datetime.datetime(2001, 3, 2, 12, 0), datetime.datetime(2001, 3, 3, 0, 0)]\n",
      "\n",
      "Corresponding time values (in units hours since 0001-01-01 00:00:00.0): \n",
      " [ 17533104.  17533116.  17533128.  17533140.  17533152.]\n"
     ]
    }
   ],
   "source": [
    "dates = [ datetime(2001,3,1)+n*timedelta(hours=12) for n in range(temp.shape[0]) ]\n",
    "print ( \"Some random dates:\\n\", dates )\n",
    "\n",
    "times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n",
    "print ( \"\\nCorresponding time values (in units %s): \" % times.units+\"\\n\", times[:] )\n",
    "\n",
    "# if we need to retreive the dates from 'time' values:\n",
    "# dates = num2date(times[:],units=times.units,calendar=times.calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing the netCDF4 dataset will create / write the dataset to the `'test.nc'` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootgrp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 4.3M Jul  1 09:58 test.nc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh test.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing netCDF variables\n",
    "\n",
    "Upon closing, this dataset of 5 x 73 x 144 float32 values, has a size of about 4.3MB on disk. Apparently, this can be reduced by using compression of the most important netCDF variables. Let's see what sort of difference this makes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 4.1M Jul  1 09:58 test.nc\r\n"
     ]
    }
   ],
   "source": [
    "rootgrp = Dataset(\"test.nc\", \"w\")   # overwrites existing file\n",
    "time = rootgrp.createDimension(\"time\", None)\n",
    "lat = rootgrp.createDimension(\"lat\", 73)\n",
    "lon = rootgrp.createDimension(\"lon\", 144)\n",
    "\n",
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",))\n",
    "latitudes = rootgrp.createVariable(\"latitude\",\"f4\",(\"lat\",))\n",
    "longitudes = rootgrp.createVariable(\"longitude\",\"f4\",(\"lon\",))\n",
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"lat\",\"lon\",), zlib=True, least_significant_digit=2)\n",
    "   # lossy compression by truncation of the data to a precision of 2 significant digits\n",
    "\n",
    "latitudes.units = \"degrees north\"\n",
    "longitudes.units = \"degrees east\"\n",
    "temp.units = \"Z\"\n",
    "times.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "times.calendar = \"gregorian\"\n",
    "\n",
    "times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n",
    "latitudes[:] = np.arange(-90,91,2.5)\n",
    "longitudes[:] = np.arange(-180,180,2.5)\n",
    "temp[0:5,:,:] = uniform(size=(5,73,144))   # some random data\n",
    "\n",
    "rootgrp.close()\n",
    "\n",
    "!ls -lh test.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... not a big difference here, but might be different for larger and/or different datasets. Probably worth keeping in mind in any case.\n",
    "\n",
    "### Appending to netCDF dataset\n",
    "\n",
    "Once we have created the netCDF file as per above (with unlimited 'time' dimension), we can append to it as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<type 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): time(5), lat(73), lon(144)\n",
       "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mlatitude\u001b[0m(lat), float32 \u001b[4mlongitude\u001b[0m(lon), float32 \u001b[4mtemp\u001b[0m(time,lat,lon)\n",
       "    groups: "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp = Dataset(\"test.nc\", \"a\")   # open the dataset in 'append' mode\n",
    "grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Read in\" the 'temp' variable from the netCDF dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, lat, lon)\n",
      "    least_significant_digit: 2\n",
      "    units: Z\n",
      "unlimited dimensions: time\n",
      "current shape = (5, 73, 144)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.09375  ,  0.1796875,  0.609375 , ...,  0.1484375,  0.6328125,\n",
       "         0.8125   ],\n",
       "       [ 0.9921875,  0.25     ,  0.5234375, ...,  0.8671875,  0.625    ,\n",
       "         0.6953125],\n",
       "       [ 0.4453125,  0.5234375,  0.6328125, ...,  0.390625 ,  0.53125  ,\n",
       "         0.7265625],\n",
       "       ..., \n",
       "       [ 0.0078125,  0.3359375,  0.3515625, ...,  0.3515625,  0.0625   ,\n",
       "         0.3203125],\n",
       "       [ 0.328125 ,  0.109375 ,  0.8984375, ...,  0.953125 ,  0.0078125,\n",
       "         0.8046875],\n",
       "       [ 0.0703125,  0.9140625,  0.40625  , ...,  0.4609375,  0.4765625,\n",
       "         0.1640625]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = grp['temp']\n",
    "print( temp )\n",
    "temp[4,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append new data to 'temp' variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50.,  50.,  50., ...,  50.,  51.,  51.],\n",
       "       [ 51.,  51.,  51., ...,  51.,  51.,  51.],\n",
       "       [ 50.,  51.,  51., ...,  50.,  50.,  50.],\n",
       "       ..., \n",
       "       [ 51.,  50.,  50., ...,  51.,  50.,  50.],\n",
       "       [ 51.,  51.,  51., ...,  50.,  50.,  51.],\n",
       "       [ 50.,  51.,  50., ...,  50.,  50.,  50.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[5,:,:] = np.round( 50 + uniform(size=(1,73,144)) )   # some new (different) data\n",
    "temp[5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data = [17533104.0 17533116.0 17533128.0 17533140.0 17533152.0 --],\n",
       "             mask = [False False False False False  True],\n",
       "       fill_value = 9.96920996839e+36)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = grp['time']\n",
    "time[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the 'time' variable / dimension has grown by one, though the newly created index does not have a proper value assigned to it yet. Let's define it with some new date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17533104.,  17533116.,  17533128.,  17533140.,  17533152.,\n",
       "        17533224.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time[-1] = date2num( datetime(2001,3,1)+10*timedelta(hours=12), units=time.units, calendar=time.calendar)\n",
    "time[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, closing the netCDF dataset will again save the data to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 4.1M Jul  1 09:58 test.nc\r\n"
     ]
    }
   ],
   "source": [
    "grp.close()\n",
    "!ls -lh test.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load up the `.nc` file again to ensure the data has been saved properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, lat, lon)\n",
      "    least_significant_digit: 2\n",
      "    units: Z\n",
      "unlimited dimensions: time\n",
      "current shape = (6, 73, 144)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "\n",
      "[[[  9.37500000e-02   1.79687500e-01   6.09375000e-01 ...,   1.48437500e-01\n",
      "     6.32812500e-01   8.12500000e-01]\n",
      "  [  9.92187500e-01   2.50000000e-01   5.23437500e-01 ...,   8.67187500e-01\n",
      "     6.25000000e-01   6.95312500e-01]\n",
      "  [  4.45312500e-01   5.23437500e-01   6.32812500e-01 ...,   3.90625000e-01\n",
      "     5.31250000e-01   7.26562500e-01]\n",
      "  ..., \n",
      "  [  7.81250000e-03   3.35937500e-01   3.51562500e-01 ...,   3.51562500e-01\n",
      "     6.25000000e-02   3.20312500e-01]\n",
      "  [  3.28125000e-01   1.09375000e-01   8.98437500e-01 ...,   9.53125000e-01\n",
      "     7.81250000e-03   8.04687500e-01]\n",
      "  [  7.03125000e-02   9.14062500e-01   4.06250000e-01 ...,   4.60937500e-01\n",
      "     4.76562500e-01   1.64062500e-01]]\n",
      "\n",
      " [[  5.00000000e+01   5.00000000e+01   5.00000000e+01 ...,   5.00000000e+01\n",
      "     5.10000000e+01   5.10000000e+01]\n",
      "  [  5.10000000e+01   5.10000000e+01   5.10000000e+01 ...,   5.10000000e+01\n",
      "     5.10000000e+01   5.10000000e+01]\n",
      "  [  5.00000000e+01   5.10000000e+01   5.10000000e+01 ...,   5.00000000e+01\n",
      "     5.00000000e+01   5.00000000e+01]\n",
      "  ..., \n",
      "  [  5.10000000e+01   5.00000000e+01   5.00000000e+01 ...,   5.10000000e+01\n",
      "     5.00000000e+01   5.00000000e+01]\n",
      "  [  5.10000000e+01   5.10000000e+01   5.10000000e+01 ...,   5.00000000e+01\n",
      "     5.00000000e+01   5.10000000e+01]\n",
      "  [  5.00000000e+01   5.10000000e+01   5.00000000e+01 ...,   5.00000000e+01\n",
      "     5.00000000e+01   5.00000000e+01]]]\n",
      "\n",
      " <type 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: hours since 0001-01-01 00:00:00.0\n",
      "    calendar: gregorian\n",
      "unlimited dimensions: time\n",
      "current shape = (6,)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "\n",
      "[ 17533104.  17533116.  17533128.  17533140.  17533152.  17533224.]\n"
     ]
    }
   ],
   "source": [
    "grp = Dataset(\"test.nc\", \"r\")\n",
    "print( grp['temp'] )\n",
    "print( grp['temp'][(4,5),:,:] )\n",
    "print( \"\\n\", grp['time'] )\n",
    "print( grp['time'][:] )\n",
    "grp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating a netCDF dataset: method 2\n",
    "\n",
    "Another method is to merge two `.nc` files with the `ncrcat` shell command. On the VDI, this command appears to be available by default in the terminal, whereas on NCI's Raijin, it becomes available after loading the following module:\n",
    "\n",
    "```\n",
    " $ module load nco \n",
    "```\n",
    "\n",
    "Let's see how to use this option by first creating another test dataset with 10 new time slices with dates sometime in 2002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 4.1M Jul  1 09:58 test2.nc\r\n"
     ]
    }
   ],
   "source": [
    "rootgrp = Dataset(\"test2.nc\", \"w\")\n",
    "time = rootgrp.createDimension(\"time\", None)\n",
    "lat = rootgrp.createDimension(\"lat\", 73)\n",
    "lon = rootgrp.createDimension(\"lon\", 144)\n",
    "\n",
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",))\n",
    "latitudes = rootgrp.createVariable(\"latitude\",\"f4\",(\"lat\",))\n",
    "longitudes = rootgrp.createVariable(\"longitude\",\"f4\",(\"lon\",))\n",
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"lat\",\"lon\",), zlib=True, least_significant_digit=2)\n",
    "   # lossy compression by truncation of the data to a precision of 2 significant digits\n",
    "\n",
    "latitudes.units = \"degrees north\"\n",
    "longitudes.units = \"degrees east\"\n",
    "temp.units = \"Z\"\n",
    "times.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "times.calendar = \"gregorian\"\n",
    "\n",
    "temp[0:10,:,:] = np.round( 80 + uniform(size=(10,73,144)) )   # some random data\n",
    "dates = [ datetime(2002,12,1)+n*timedelta(hours=12) for n in range(temp.shape[0]) ]\n",
    "times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n",
    "latitudes[:] = np.arange(-90,91,2.5)\n",
    "longitudes[:] = np.arange(-180,180,2.5)\n",
    "\n",
    "rootgrp.close()\n",
    "\n",
    "!ls -lh test2.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the two `test.nc` and `test2.nc` files. We should be able to concatenate them using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 4.1M Jul  1 09:58 test_all.nc\r\n"
     ]
    }
   ],
   "source": [
    "!ncrcat test.nc test2.nc -O test_all.nc\n",
    "!ls -lh test_all.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have worked OK (though it's unclear why the new dataset is of similar size to the original datasets). Let's check whether this new concatenated dataset has been correctly generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Variable'>\n",
      "float32 temp(time, lat, lon)\n",
      "    least_significant_digit: 2\n",
      "    units: Z\n",
      "unlimited dimensions: time\n",
      "current shape = (16, 73, 144)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "\n",
      "[[[  9.37500000e-02   1.79687500e-01   6.09375000e-01 ...,   1.48437500e-01\n",
      "     6.32812500e-01   8.12500000e-01]\n",
      "  [  9.92187500e-01   2.50000000e-01   5.23437500e-01 ...,   8.67187500e-01\n",
      "     6.25000000e-01   6.95312500e-01]\n",
      "  [  4.45312500e-01   5.23437500e-01   6.32812500e-01 ...,   3.90625000e-01\n",
      "     5.31250000e-01   7.26562500e-01]\n",
      "  ..., \n",
      "  [  7.81250000e-03   3.35937500e-01   3.51562500e-01 ...,   3.51562500e-01\n",
      "     6.25000000e-02   3.20312500e-01]\n",
      "  [  3.28125000e-01   1.09375000e-01   8.98437500e-01 ...,   9.53125000e-01\n",
      "     7.81250000e-03   8.04687500e-01]\n",
      "  [  7.03125000e-02   9.14062500e-01   4.06250000e-01 ...,   4.60937500e-01\n",
      "     4.76562500e-01   1.64062500e-01]]\n",
      "\n",
      " [[  5.00000000e+01   5.00000000e+01   5.00000000e+01 ...,   5.00000000e+01\n",
      "     5.10000000e+01   5.10000000e+01]\n",
      "  [  5.10000000e+01   5.10000000e+01   5.10000000e+01 ...,   5.10000000e+01\n",
      "     5.10000000e+01   5.10000000e+01]\n",
      "  [  5.00000000e+01   5.10000000e+01   5.10000000e+01 ...,   5.00000000e+01\n",
      "     5.00000000e+01   5.00000000e+01]\n",
      "  ..., \n",
      "  [  5.10000000e+01   5.00000000e+01   5.00000000e+01 ...,   5.10000000e+01\n",
      "     5.00000000e+01   5.00000000e+01]\n",
      "  [  5.10000000e+01   5.10000000e+01   5.10000000e+01 ...,   5.00000000e+01\n",
      "     5.00000000e+01   5.10000000e+01]\n",
      "  [  5.00000000e+01   5.10000000e+01   5.00000000e+01 ...,   5.00000000e+01\n",
      "     5.00000000e+01   5.00000000e+01]]\n",
      "\n",
      " [[  8.00000000e+01   8.00000000e+01   8.10000000e+01 ...,   8.10000000e+01\n",
      "     8.10000000e+01   8.10000000e+01]\n",
      "  [  8.00000000e+01   8.00000000e+01   8.00000000e+01 ...,   8.10000000e+01\n",
      "     8.00000000e+01   8.00000000e+01]\n",
      "  [  8.10000000e+01   8.10000000e+01   8.00000000e+01 ...,   8.10000000e+01\n",
      "     8.10000000e+01   8.00000000e+01]\n",
      "  ..., \n",
      "  [  8.10000000e+01   8.10000000e+01   8.10000000e+01 ...,   8.10000000e+01\n",
      "     8.00000000e+01   8.00000000e+01]\n",
      "  [  8.00000000e+01   8.00000000e+01   8.00000000e+01 ...,   8.00000000e+01\n",
      "     8.00000000e+01   8.00000000e+01]\n",
      "  [  8.10000000e+01   8.10000000e+01   8.00000000e+01 ...,   8.10000000e+01\n",
      "     8.10000000e+01   8.10000000e+01]]]\n",
      "\n",
      " <type 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: hours since 0001-01-01 00:00:00.0\n",
      "    calendar: gregorian\n",
      "unlimited dimensions: time\n",
      "current shape = (16,)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "\n",
      "[datetime.datetime(2001, 3, 1, 0, 0) datetime.datetime(2001, 3, 1, 12, 0)\n",
      " datetime.datetime(2001, 3, 2, 0, 0) datetime.datetime(2001, 3, 2, 12, 0)\n",
      " datetime.datetime(2001, 3, 3, 0, 0) datetime.datetime(2001, 3, 6, 0, 0)\n",
      " datetime.datetime(2002, 12, 1, 0, 0) datetime.datetime(2002, 12, 1, 12, 0)\n",
      " datetime.datetime(2002, 12, 2, 0, 0) datetime.datetime(2002, 12, 2, 12, 0)\n",
      " datetime.datetime(2002, 12, 3, 0, 0) datetime.datetime(2002, 12, 3, 12, 0)\n",
      " datetime.datetime(2002, 12, 4, 0, 0) datetime.datetime(2002, 12, 4, 12, 0)\n",
      " datetime.datetime(2002, 12, 5, 0, 0) datetime.datetime(2002, 12, 5, 12, 0)]\n"
     ]
    }
   ],
   "source": [
    "grp = Dataset(\"test_all.nc\", \"r\")\n",
    "print( grp['temp'] )\n",
    "print( grp['temp'][(4,5,6),:,:] )\n",
    "print( \"\\n\", grp['time'] )\n",
    "time = grp['time'][:]\n",
    "print( num2date(times[:],units=times.units,calendar=times.calendar) )\n",
    "grp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems OK, with not 16 dates in total (the first few in 2001, and last few in 2002), and correctly concatenated 'temp' variable.\n",
    "\n",
    "As a final check, let's see if the `ncrcat` option also works with more \"basic\" `.nc` datasets, created without an unlimited dimension, and without variables compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 131K Jul  1 09:58 test.nc\r\n"
     ]
    }
   ],
   "source": [
    "rootgrp = Dataset(\"test.nc\", \"w\")\n",
    "time = rootgrp.createDimension(\"time\", 3)   # not unlimited!\n",
    "lat = rootgrp.createDimension(\"lat\", 73)\n",
    "lon = rootgrp.createDimension(\"lon\", 144)\n",
    "\n",
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",))\n",
    "latitudes = rootgrp.createVariable(\"latitude\",\"f4\",(\"lat\",))\n",
    "longitudes = rootgrp.createVariable(\"longitude\",\"f4\",(\"lon\",))\n",
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"lat\",\"lon\",))\n",
    "\n",
    "temp[0:3,:,:] = np.round( 5 + uniform(size=(3,73,144)) )   # some random data\n",
    "dates = [ datetime(2002,12,1)+n*timedelta(hours=1) for n in range(temp.shape[0]) ]\n",
    "times[:] = date2num(dates, units=\"hours since 0001-01-01 00:00:00.0\", calendar=\"gregorian\")\n",
    "latitudes[:] = np.arange(-90,91,2.5)\n",
    "longitudes[:] = np.arange(-180,180,2.5)\n",
    "\n",
    "rootgrp.close()\n",
    "!ls -lh test.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 eal599 jr4 90K Jul  1 09:58 test2.nc\r\n"
     ]
    }
   ],
   "source": [
    "rootgrp = Dataset(\"test2.nc\", \"w\")\n",
    "time = rootgrp.createDimension(\"time\", 2)   # not unlimited!\n",
    "lat = rootgrp.createDimension(\"lat\", 73)\n",
    "lon = rootgrp.createDimension(\"lon\", 144)\n",
    "\n",
    "times = rootgrp.createVariable(\"time\",\"f8\",(\"time\",))\n",
    "latitudes = rootgrp.createVariable(\"latitude\",\"f4\",(\"lat\",))\n",
    "longitudes = rootgrp.createVariable(\"longitude\",\"f4\",(\"lon\",))\n",
    "temp = rootgrp.createVariable(\"temp\",\"f4\",(\"time\",\"lat\",\"lon\",))\n",
    "\n",
    "temp[0:2,:,:] = np.round( 2 + uniform(size=(2,73,144)) )   # some random data\n",
    "dates = [ datetime(2003,1,1)+n*timedelta(hours=1) for n in range(temp.shape[0]) ]\n",
    "times[:] = date2num(dates, units=\"hours since 0001-01-01 00:00:00.0\", calendar=\"gregorian\")\n",
    "latitudes[:] = np.arange(-90,91,2.5)\n",
    "longitudes[:] = np.arange(-180,180,2.5)\n",
    "\n",
    "rootgrp.close()\n",
    "!ls -lh test2.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncrcat: ERROR no variables fit criteria for processing\r\n",
      "ncrcat: HINT Extraction list must contain a record variable which to concatenate. A record variable is a variable defined with a record dimension. Often the record dimension, aka unlimited dimension, refers to time. For more information on creating record dimensions within existing datasets, see http://nco.sf.net/nco.html#mk_rec_dmn\r\n"
     ]
    }
   ],
   "source": [
    "!ncrcat test.nc test2.nc -O test_all.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OK, so it looks like to be able to use this option, our WQ datasets will have to have the time variable defined as unlimited."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
